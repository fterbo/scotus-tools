#!/usr/bin/env python

# Copyright (c) 2018-2022  Floyd Terbo

import functools
import json
import logging
import os
from pathos import multiprocessing
import sys
import time

import scotus.exceptions
import scotus.filters
import scotus.outputs
import scotus.queries
import scotus.sources

# analysis-engine '{"sources" : [["docket", {"term" : 17, "paid" : true, "ifp" : true}]],
#                   "filters" : [["lowercourt", {"court_abbrev" : "scFL"}]],
#                   "queries" : [["petition-ngram", {"query_term" : "qualified immunity", "min_count" : 2}]],
#                   "output" : ["docket-oneline", {}]}'

PROCESSES = 8

scotus.exceptions.CasenameError.IGNORE = True

def apply_filters (filter_list, sinfo):
  for srcf in filter_list:
    if not srcf.include(sinfo):
      return None
  return sinfo


def apply_query (query_list, sinfo):
  qout_data = []
  for qc in query_list:
    qout = qc.query(sinfo)
    if qout:
      qout_data.append(qout)
  if len(qout_data) == len(query_list):
    outd = {}
    for (ref, extra) in qout_data:
      outd.setdefault(ref, []).append(extra)
    return outd
  return {}



def engine (sources, output, filters = [], queries = [], rejects = []):
  source_list = []
  for (sname, sargs) in sources:
    source_list.append(scotus.sources.SOURCETYPES[sname](root_path = ".", **sargs))

  filter_list = []
  for (fname, fargs) in filters:
    filter_list.append(scotus.filters.FILTERTYPES[fname](**fargs))

  reject_list = []
  for (rfname, rfargs) in rejects:
    reject_list.append(scotus.filters.FILTERTYPES[rfname](**rfargs))

  query_list = []
  for (qname, qargs) in queries:
    query_list.append(scotus.queries.QUERYTYPES[qname](**qargs))

  outklass = scotus.outputs.OUTPUTTYPES[output[0]](**output[1])

  fpool = multiprocessing.ProcessingPool(nodes = PROCESSES)

  filtered_source_list = []
  if filter_list:
    for source in source_list:
      res = fpool.amap(functools.partial(apply_filters, filter_list), [item for item in source])
      while not res.ready():
        time.sleep(0.5)
      for sinfo in res.get():
        if sinfo:
          filtered_source_list.append(sinfo)
  else:
    for source in source_list:
      filtered_source_list.extend([item for item in source])

  logging.debug("Filtered sources: %d" % (len(filtered_source_list)))

  rejected_source_set = set(filtered_source_list)
  if reject_list:
    res = fpool.amap(functools.partial(apply_filters, reject_list), [item for item in filtered_source_list])
    while not res.ready():
      time.sleep(0.5)
    for sinfo in res.get():
      if sinfo:
        rejected_source_set.discard(sinfo)
    rejected_source_list = sorted(list(rejected_source_set))
  else:
    rejected_source_list = filtered_source_list

  logging.debug("Sources after rejection: %d" % (len(rejected_source_list)))
 
  qpool = multiprocessing.ProcessingPool(nodes = PROCESSES)
  if query_list:
    query_out = []
    res = qpool.amap(functools.partial(apply_query, query_list), [item for item in rejected_source_list])
    while not res.ready():
      time.sleep(0.5)
    for rinfo in res.get():
      for k,v in rinfo.items():
        query_out.append((k, v))
#    query_out = []
#    for sdata in filtered_source_list:
#      qdata = apply_query(query_list, sdata)
#      for k,v in qdata.items():
#        query_out.append((k,v))
  else:
    query_out = [(x, []) for x in rejected_source_list]

  out = []
  for k,v in query_out:
    out.append(outklass.output(k, v))

  return out
    

if __name__ == '__main__':
  if os.getenv("SCOTUSDEBUG"):
    logging.basicConfig(level=logging.DEBUG)
  else:
    logging.basicConfig(level=logging.INFO)

  if os.getenv("SCOTUSTHREADS"):
    PROCESSES = int(os.getenv("SCOTUSTHREADS"))

  logging.info("Using %d jobs" % (PROCESSES))

  kwargs = json.loads(sys.argv[1])
  out = engine(**kwargs)
  d = {"v" : 1, "arguments" : kwargs, "output" : out}
  s = json.dumps(d)
  print s
