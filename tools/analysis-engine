#!/usr/bin/env python

# Copyright (c) 2018  Floyd Terbo

import functools
import json
import logging
import os
from pathos import multiprocessing
import sys
import time

import scotus.filters
import scotus.outputs
import scotus.queries
import scotus.sources

# analysis-engine '{"sources" : [["docket", {"term" : 17, "paid" : true, "ifp" : true}]],
#                   "filters" : [["lowercourt", {"court_abbrev" : "scFL"}]],
#                   "queries" : [["petition-ngram", {"query_term" : "qualified immunity", "min_count" : 2}]],
#                   "output" : ["docket-oneline", {}]}'

PROCESSES = 8

def apply_filters (filter_list, sinfo):
  for srcf in filter_list:
    if not srcf.include(sinfo):
      return None
  return sinfo


def apply_query (query_list, sinfo):
  qout_data = []
  for qc in query_list:
    qout = qc.query(sinfo)
    if qout:
      qout_data.append(qout)
  if len(qout_data) == len(query_list):
    outd = {}
    for (ref, extra) in qout_data:
      outd.setdefault(ref, []).append(extra)
    return outd
  return {}



def engine (sources, filters, queries, output):
  source_list = []
  for (sname, sargs) in sources:
    source_list.append(scotus.sources.SOURCETYPES[sname](root_path = ".", **sargs))

  filter_list = []
  for (fname, fargs) in filters:
    filter_list.append(scotus.filters.FILTERTYPES[fname](**fargs))

  query_list = []
  for (qname, qargs) in queries:
    query_list.append(scotus.queries.QUERYTYPES[qname](**qargs))

  outklass = scotus.outputs.OUTPUTTYPES[output[0]](**output[1])

  fpool = multiprocessing.ProcessingPool(nodes = PROCESSES)

  filtered_source_list = []
  if filter_list:
    for source in source_list:
      res = fpool.amap(functools.partial(apply_filters, filter_list), [item for item in source])
      while not res.ready():
        time.sleep(0.5)
      for sinfo in res.get():
        if sinfo:
          filtered_source_list.append(sinfo)
  else:
    for source in source_list:
      filtered_source_list.extend([item for item in source])

  logging.debug("Filtered sources: %d" % (len(filtered_source_list)))
 
  qpool = multiprocessing.ProcessingPool(nodes = PROCESSES)
  if query_list:
    query_out = []
    res = qpool.amap(functools.partial(apply_query, query_list), [item for item in filtered_source_list])
    while not res.ready():
      time.sleep(0.5)
    for rinfo in res.get():
      for k,v in rinfo.items():
        query_out.append((k, v))
#    query_out = []
#    for sdata in filtered_source_list:
#      qdata = apply_query(query_list, sdata)
#      for k,v in qdata.items():
#        query_out.append((k,v))
  else:
    query_out = [(x, []) for x in filtered_source_list]

  out = []
  for k,v in query_out:
    out.append(outklass.output(k, v))

  return out
    

if __name__ == '__main__':
  if os.getenv("SCOTUSDEBUG"):
    logging.basicConfig(level=logging.DEBUG)
  else:
    logging.basicConfig(level=logging.INFO)

  kwargs = json.loads(sys.argv[1])
  out = engine(**kwargs)
  d = {"v" : 1, "arguments" : kwargs, "output" : out}
  s = json.dumps(d)
  print s
