#!/usr/bin/env python

# Copyright (c) 2018-2021  Floyd Terbo

import argparse
import datetime
import json
import logging
import os
import os.path
import sys
import time
import urllib

import BeautifulSoup as BS
import requests

import scotus.util

HEADERS = {"User-Agent" : "SCOTUS Docket Grabber (https://github.com/fterbo/scotus-tools)"}
BASE = "https://www.supremecourt.gov/rss/cases/JSON/"

def GET (url):
  logging.debug("GET: %s" % (url))
  return requests.get(url, headers=HEADERS)

class SkipDocket(Exception): pass

def parse_args ():
  parser = argparse.ArgumentParser()
  parser.add_argument("-t", "--term", dest="term", type=int)
  parser.add_argument("-o", "--orig", dest="orig", default = False, action="store_true")
  parser.add_argument("-A", "--application", dest="application", default=False, action="store_true")
  parser.add_argument("-n", "--docket-num", dest="docket_num", type=int)
  parser.add_argument("-a", "--action", dest="action", type=str, default="scan-petition")
  parser.add_argument("--dry-run", dest="dry_run", action="store_true")
  parser.add_argument("--debug", dest="debug", action="store_true")
  parser.add_argument("--stop", dest="stop", type=int, default=0)
  parser.add_argument("--root", dest="root", type=str, default=".")
  args = parser.parse_args()
  return args

def updateDockets (path, opts):
  nextnum = opts.docket_num
  while True:
    try:
      if nextnum > opts.stop:
        return

      newpath = "%s/%d/" % (path, nextnum)
      docketstr = scotus.util.buildDocketStr(opts, nextnum)

      if not os.path.exists(newpath):
        if nextnum < opts.stop:
          raise SkipDocket()
        return

      dinfopath = "%s/docket.json" % (newpath)
      if not os.path.exists(dinfopath):
        raise SkipDocket()

      docket_obj = json.loads(open(dinfopath, "rb").read())
      docket = scotus.util.DocketStatusInfo(docket_obj)

      # If the docket has been dismissed, denied, or has an issued judgment, you'll have to update it
      # by hand if you know it has new data
      if not docket.pending:
        raise SkipDocket()

      # Don't update the docket if it's scheduled for a conference in the future
      if docket.distributed:
        if datetime.date.today() < docket.distributed[-1][1]:
          raise SkipDocket()

      logging.info("Updating pending docket (%s)" % (docketstr))
      if opts.dry_run:
        raise SkipDocket()

      url = "%s%s.json" % (BASE, docketstr)
      r = GET(url)
      if r.status_code != 200:
        logging.info("Skipping <%s> with bad status [%d]" % (url, r.status_code))
        raise SkipDocket()

      with open(dinfopath, "w+") as f:
        f.write(json.dumps(r.json()))

      nextnum += 1

    except SkipDocket:
      nextnum += 1

    


# TODO: We really should use some exceptions to better handle control flow
def scanPetitions (path, opts):
  nextnum = opts.docket_num
  while True:
    newpath = "%s/%d/" % (path, nextnum)
    docketstr = scotus.util.buildDocketStr(opts, nextnum)

    if os.path.exists("%s/docket.json" % (newpath)):
      # We already scanned this docket
      nextnum += 1
      continue

    url = "%s%s.json" % (BASE, docketstr)
    time.sleep(0.75)
    r = GET(url)
    if r.status_code != 200:
      if opts.stop and nextnum < opts.stop:
        logging.info("Skipping <%s> with no docket [STATUS: %d]" % (url, r.status_code))
        nextnum += 1
        continue
      else:
        logging.info("Stopped for URL <%s> with code %d" % (url, r.status_code))
        break

    docket_obj = r.json()
    founditem = None
    for item in docket_obj["ProceedingsandOrder"]:
      try:
        for link in item["Links"]:
          if (link["Description"] == "Petition" or
              link["Description"] == "Motion for Leave to File a Bill of Complaint"):
            founditem = item
            break
        if founditem:
          break
      except KeyError:
        # Likely original extension of time to file
        logging.debug("[%s] No links: %s" % (docketstr, item["Text"]))
        continue

    try:
      os.makedirs(newpath)
    except OSError:
      pass # Should check errno, but probably already exists

    with open("%s/docket.json" % (newpath), "w+") as f:
      f.write(json.dumps(r.json()))

    if not founditem:
      logging.error("Couldn't find a petition for docket %s" % (docketstr))
      nextnum += 1
      continue

    match = list(set(founditem["Text"].split()) & scotus.util.PETITION_TYPES)
    try:
      casename = scotus.util.buildCasename(docket_obj)
    except scotus.exceptions.SCOTUSError as e:
      logging.exception(str(e))

    if len(match) == 0:
      logging.warning("[%s] Unknown petition type for: %s" % (docketstr, founditem["Text"]))
    elif len(match) == 1:
      logging.info("[%s] (%s) %s" % (docketstr, match[0], casename))
    elif len(match) > 1:
      logging.info("[%s] Too many type matches for: %s" % (docketstr, founditem["Text"]))

    for link in founditem["Links"]:
      if link["Description"] in scotus.util.PETITION_LINKS:
        outpath = "%s/%s" % (newpath, link["File"])
        if os.path.exists(outpath):
          continue
        logging.debug("[%s] Downloading %s" % (docketstr, link["File"]))
        dl = GET(link["DocumentUrl"])
        if dl.status_code != 200:
          logging.error("[%s] FAILED: %d" % (docketstr, dl.status_code))
          continue
        with open(outpath, "w+") as f:
          f.write(dl.content)

    nextnum += 1
        

def scanApplications (path, opts):
  nextnum = opts.docket_num
  while True:
    newpath = "%s/%d"% (path, nextnum)
    docketstr = scotus.util.buildDocketStr(opts, nextnum)

    if os.path.exists("%s/docket.json" % (newpath)):
      # We already scanned this docket
      nextnum += 1
      continue

    url = "%s%s.json" % (BASE, docketstr)
    r = GET(url)
    if r.status_code != 200:
      if opts.stop and nextnum < opts.stop:
        logging.info("Skipping <%s> with no docket [STATUS: %d]" % (url, r.status_code))
        nextnum += 1
        continue
      else:
        logging.info("Stopped for URL <%s> with code %d" % (url, r.status_code))
        break

    try:
      os.makedirs(newpath)
    except OSError:
      pass # Should check errno, but probably already exists

    try:
      docket_obj = r.json()
      with open("%s/docket.json" % (newpath), "w+") as f:
        f.write(json.dumps(r.json()))
    except ValueError:
      logging.error("Invalid JSON for %s" % (docketstr))
      nextnum += 1
      continue

    founditem = None
    for item in docket_obj["ProceedingsandOrder"]:
      try:
        for link in item["Links"]:
          if (link["Description"] == "Main Document"):
            logging.info("[%s] %s" % (docketstr, item["Text"]))
            founditem = item
            break
        if founditem:
          break
      except KeyError:
        # Likely original extension of time to file
        logging.debug("[%s] No links: %s" % (docketstr, item["Text"]))
        continue

    if not founditem:
      logging.error("Couldn't find application text for docket %s" % (docketstr))
      nextnum += 1
      continue



# TODO: we should optionally allow checking last-modified with HEAD before we grab if the caller
# is doing a larger scan where many are unlikely to be updated since last scan
def downloadFull (path, opts):
  docketstr = scotus.util.buildDocketStr(opts)
  newpath = "%s/%d/" % (path, opts.docket_num)
  try:
    os.makedirs(newpath)
  except OSError:
    pass

  logging.info("Processing docket %s" % (docketstr))

  url = "%s%s.json" % (BASE, docketstr)
  r = GET(url)
  if r.status_code != 200:
    logging.error("Could not get docket metadata <%s> with code %d" % (url, r.status_code))
    sys.exit(1)

  docket_obj = r.json()
  with open("%s/docket.json" % (newpath), "w+") as df:
    df.write(json.dumps(docket_obj))

  for item in docket_obj["ProceedingsandOrder"]:
    if "Links" not in item:
      continue
    for link in item["Links"]:
      if "DocumentUrl" not in link:
        logging.warning("Found link without DocumentUrl: %s" % (link["Description"]))
        continue
      fname = urllib.unquote_plus(link["DocumentUrl"].split("/")[-1])
      outpath = "%s/%s" % (newpath, fname)
      if os.path.exists(outpath):
        continue
      time.sleep(0.25)
      logging.info("[%s] Downloading %s" % (docketstr, fname))
      dl = GET(link["DocumentUrl"])
      if dl.status_code == 403:
        logging.warning("[%s] Waiting 180 seconds" % (docketstr))
        time.sleep(180)
        dl = GET(link["DocumentUrl"])
      if dl.status_code != 200:
        logging.error("[%s] FAILED: %d" % (docketstr, dl.status_code))
        if dl.status_code == 403:
          sys.exit()
        continue
      with open(outpath, "w+") as f:
        f.write(dl.content)


ACTIONS = {
  "scan-petition" : scanPetitions,
  "petitions" : scanPetitions,
  "scan-applications" : scanApplications,
  "download-full" : downloadFull,
  "download" : downloadFull,
  "update" : updateDockets,
}

if __name__ == '__main__':
  opts = parse_args()
  if opts.action.count("application"):
    opts.application = True

  if opts.debug:
    logging.basicConfig(level=logging.DEBUG)
  else:
    logging.basicConfig(level=logging.INFO)

  if opts.orig:
    path = "%s/Orig/dockets" % (opts.root)
  elif opts.application:
    path = "%s/OT-%d/dockets/A" % (opts.root, opts.term)
  else:
    path = "%s/OT-%d/dockets" % (opts.root, opts.term)

  try:
    os.makedirs(path)
  except OSError:
    pass

  if opts.action.count("petition") and opts.application:
    func = ACTIONS["scan-applications"]
  else:
    func = ACTIONS[opts.action]

  func(path, opts)
